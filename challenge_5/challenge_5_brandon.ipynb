{
  "cells": [
    {
      "cell_type": "code",
      "id": "s9rvlEh7rEQkWw0gJbXsgf8A",
      "metadata": {
        "tags": [],
        "id": "s9rvlEh7rEQkWw0gJbXsgf8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "87304f9e-98fd-40f6-b630-213003820514"
      },
      "source": [
        "!pip install --upgrade google-genai\n",
        "!pip install pytest ipytest\n",
        "!pip install --upgrade google-cloud-aiplatform google-cloud-aiplatform[generativeai]"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.10/dist-packages (1.12.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-genai) (2.27.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-genai) (2.10.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.10/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from google-genai) (14.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.10/dist-packages (from google-genai) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (8.3.4)\n",
            "Requirement already satisfied: ipytest in /usr/local/lib/python3.10/dist-packages (0.14.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.2.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.2.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (69.5.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipytest) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipytest) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipytest) (0.2.13)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.74.0)\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.90.0-py2.py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (4.25.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.31.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.10.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "\u001b[33mWARNING: google-cloud-aiplatform 1.90.0 does not provide the extra 'generativeai'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.27.2)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0->google-cloud-aiplatform) (1.26.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2024.12.14)\n",
            "Downloading google_cloud_aiplatform-1.90.0-py2.py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-aiplatform\n",
            "  Attempting uninstall: google-cloud-aiplatform\n",
            "    Found existing installation: google-cloud-aiplatform 1.74.0\n",
            "    Uninstalling google-cloud-aiplatform-1.74.0:\n",
            "      Successfully uninstalled google-cloud-aiplatform-1.74.0\n",
            "Successfully installed google-cloud-aiplatform-1.90.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "vertexai"
                ]
              },
              "id": "77d8297d85f54d74808471330b3711b9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vector search\n",
        "import json\n",
        "from google.cloud import bigquery\n",
        "\n",
        "def vector_search(user_question):\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  sql = \"\"\"\n",
        "  SELECT query.query,base.question, base.answer\n",
        "  FROM VECTOR_SEARCH(\n",
        "  TABLE `qwiklabs-gcp-01-3005c83a3aae.ADS.alaska_dept_of_snow_with_embeddings`, 'ml_generate_embedding_result',\n",
        "  (\n",
        "  SELECT ml_generate_embedding_result,content AS query\n",
        "  FROM ML.GENERATE_EMBEDDING(\n",
        "  MODEL `qwiklabs-gcp-01-3005c83a3aae.ADS.Embeddings`,\n",
        "  (SELECT @user_question AS content))),\n",
        "  top_k => 5,\n",
        "  options => '{\"fraction_lists_to_search\": 0.01}');\n",
        "  \"\"\"\n",
        "  # sql = \"\"\"\n",
        "  # SELECT query.query, base.question, base.answer, distance\n",
        "  # FROM VECTOR_SEARCH(\n",
        "  # TABLE `qwiklabs-gcp-01-3005c83a3aae.faq.aurora_faq_with_embeddings`, 'ml_generate_embedding_result',\n",
        "  # (\n",
        "  # SELECT text_embedding, content AS query\n",
        "  # FROM ML.GENERATE_TEXT_EMBEDDING(\n",
        "  # MODEL `qwiklabs-gcp-01-3005c83a3aae.faq.embedding_model`,\n",
        "  # (SELECT @user_question AS content))\n",
        "  # ),\n",
        "  # top_k => 5, options => '{\"fraction_lists_to_search\": 0.01}')\n",
        "  # \"\"\"\n",
        "\n",
        "  job_config = bigquery.QueryJobConfig(\n",
        "      query_parameters=[\n",
        "          bigquery.ScalarQueryParameter(\"user_question\", \"STRING\", user_question),\n",
        "          # Options must be passed as a JSON string\n",
        "          bigquery.ScalarQueryParameter(\"search_options\", \"JSON\", json.dumps({\"fraction_lists_to_search\": 0.01}))\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    # Start the query job.\n",
        "    # print(f\"Executing vector search for: '{user_question}'\")\n",
        "    query_job = client.query(sql, job_config=job_config)\n",
        "\n",
        "    # Wait for the job to complete and fetch results.\n",
        "    results = query_job.result() # Waits for job completion\n",
        "\n",
        "    # Process results into a more usable format (list of dictionaries)\n",
        "    output_rows = []\n",
        "    for row in results:\n",
        "        output_rows.append({\n",
        "            \"query\": row.query,\n",
        "            \"question\": row.question,\n",
        "            \"answer\": row.answer,\n",
        "            # \"distance\": row.distance\n",
        "        })\n",
        "\n",
        "    # print(f\"Found {len(output_rows)} similar questions.\")\n",
        "    return output_rows\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred during the BigQuery vector search: {e}\")\n",
        "      return []\n",
        "\n",
        "\n",
        "result = vector_search(\"weather\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "sLLIZzupYj6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8af0cc7-eda4-4353-f8fb-8ed930f0ae97"
      },
      "id": "sLLIZzupYj6L",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'query': 'weather', 'question': 'Where does ADS get its weather forecasts?', 'answer': 'ADS partners with the National Weather Service and maintains localized weather monitoring stations for more precise data across diverse regions.'}, {'query': 'weather', 'question': 'How do schools typically learn about impending storms?', 'answer': 'ADS shares forecast data with school districts, which helps superintendents decide on closures or delays based on road safety and storm severity.'}, {'query': 'weather', 'question': 'How can I check current road conditions statewide?', 'answer': 'Use the ADS “SnowLine” app or visit the official ADS website’s road conditions dashboard, which is updated hourly with closures and warnings.'}, {'query': 'weather', 'question': 'Does ADS oversee school closure decisions?', 'answer': 'While ADS provides data on snow conditions, final school closure decisions are made by local school districts. ADS coordinates closely to keep them informed.'}, {'query': 'weather', 'question': 'Can I request data on ADS’s annual snowfall measurements?', 'answer': 'Yes. ADS publishes annual snowfall reports and statistics on its website. You can also file a public records request for more detailed data.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt formation\n",
        "def format_prompt(user_question, results):\n",
        "  output = f\"User Query: {user_question} \\n\\nUse the relevant information below to help the user:\"\n",
        "  for result in results:\n",
        "    output = output + \"\\n\\n\" + \"Question: \" + result.get(\"question\") + \"\\n\" + \"Answer: \" +result.get(\"answer\")\n",
        "\n",
        "  return output\n",
        "\n",
        "print(format_prompt(\"Weather\", result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Y5kmD6chfR",
        "outputId": "888d595a-f17e-4cab-bc78-519c6dc12f75"
      },
      "id": "g1Y5kmD6chfR",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Query: Weather \n",
            "\n",
            "Use the relevant information below to help the user:\n",
            "\n",
            "Question: Where does ADS get its weather forecasts?\n",
            "Answer: ADS partners with the National Weather Service and maintains localized weather monitoring stations for more precise data across diverse regions.\n",
            "\n",
            "Question: How do schools typically learn about impending storms?\n",
            "Answer: ADS shares forecast data with school districts, which helps superintendents decide on closures or delays based on road safety and storm severity.\n",
            "\n",
            "Question: How can I check current road conditions statewide?\n",
            "Answer: Use the ADS “SnowLine” app or visit the official ADS website’s road conditions dashboard, which is updated hourly with closures and warnings.\n",
            "\n",
            "Question: Does ADS oversee school closure decisions?\n",
            "Answer: While ADS provides data on snow conditions, final school closure decisions are made by local school districts. ADS coordinates closely to keep them informed.\n",
            "\n",
            "Question: Can I request data on ADS’s annual snowfall measurements?\n",
            "Answer: Yes. ADS publishes annual snowfall reports and statistics on its website. You can also file a public records request for more detailed data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weather tool\n",
        "import vertexai\n",
        "from vertexai.generative_models import (\n",
        "    GenerativeModel,\n",
        "    Part,\n",
        "    Tool,\n",
        "    FunctionDeclaration,\n",
        "    # FunctionResponse, # Although not used directly in definition, needed for response\n",
        "    Content          # Needed for sending history back\n",
        ")\n",
        "from google.cloud import aiplatform_v1beta1 as aiplatform\n",
        "import json # For handling function args and response content\n",
        "import requests\n",
        "import datetime\n",
        "from google.genai import types\n",
        "\n",
        "def get_weather():\n",
        "  latitude, longitude = 57.790001, -152.407227\n",
        "\n",
        "  point_url = f'https://api.weather.gov/points/{latitude},{longitude}'\n",
        "\n",
        "  headers = {\n",
        "    'User-Agent': 'brandon.leung@clearobject.com',  # NWS requires a user-agent. Enter your email\n",
        "    'Accept': 'application/ld+json'\n",
        "  }\n",
        "\n",
        "  try:\n",
        "    # Step 1: Get gridpoint info\n",
        "    point_response = requests.get(point_url, headers=headers, timeout=10)\n",
        "    point_response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "    grid_data = point_response.json()\n",
        "    forecast_url = point_response.json()['forecast']\n",
        "    if not forecast_url:\n",
        "          print(\"Error: Could not find 'forecast' URL in point response.\")\n",
        "          return \"Error: Could not retrieve forecast URL.\"\n",
        "\n",
        "    # Step 2: Get forecast from URL\n",
        "    forecast_response = requests.get(forecast_url, headers=headers, timeout=10)\n",
        "    forecast_response.raise_for_status()\n",
        "    forecast_json = forecast_response.json()\n",
        "    periods = forecast_json.get('periods')\n",
        "    if not periods:\n",
        "        print(\"Error: Could not find 'periods' in forecast response.\")\n",
        "        return \"Error: Could not retrieve forecast periods.\"\n",
        "\n",
        "\n",
        "    # Step 3: Format forecast periods\n",
        "    now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    output = f\"Weather Report for Kodiak, AK at {now}:\\n\\n\"\n",
        "    for period in periods:\n",
        "          name = period.get('name', 'Unnamed Period')\n",
        "          forecast = period.get('detailedForecast', 'No details available.')\n",
        "          output += f\"- {name}: {forecast}\\n\"\n",
        "\n",
        "    return output\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during NWS API request: {e}\")\n",
        "        return f\"Error: Unable to connect to the weather service ({e}).\"\n",
        "  except Exception as e:\n",
        "        # Catch other potential errors (like JSON parsing issues)\n",
        "        print(f\"An unexpected error occurred in get_weather: {e}\")\n",
        "        return \"Error: An unexpected issue occurred while fetching weather.\"\n",
        "\n",
        "get_weather_declaration = {\n",
        "    \"name\": \"get_weather\",\n",
        "    \"description\": \"Fetches the current weather forecast for Alaska from the US National Weather Service (NWS).\"\n",
        "}\n",
        "\n",
        "weather_function_declaration = types.FunctionDeclaration(\n",
        "    name=get_weather_declaration[\"name\"],\n",
        "    description=get_weather_declaration[\"description\"],\n",
        "    parameters=types.Schema(\n",
        "        type='OBJECT',\n",
        "        properties={},\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "# Create the Tool object containing the function declaration\n",
        "weather_tool = types.Tool(\n",
        "    function_declarations=[weather_function_declaration],\n",
        ")\n",
        "\n",
        "print(get_weather())\n",
        "# print(weather_tool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cG_21hi4POB",
        "outputId": "d2b0a6ef-8459-4c2e-b8a9-a1f23b13b126"
      },
      "id": "7cG_21hi4POB",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weather Report for Kodiak, AK at 2025-04-29 22:52:12:\n",
            "\n",
            "- This Afternoon: Snow showers likely. Mostly cloudy, with a high near 42. South wind around 10 mph, with gusts as high as 25 mph. Chance of precipitation is 70%.\n",
            "- Tonight: Snow showers likely before 7pm, then rain and snow showers likely. Mostly cloudy, with a low around 33. Southeast wind 5 to 10 mph, with gusts as high as 25 mph. Chance of precipitation is 70%.\n",
            "- Wednesday: A chance of snow showers before 7am, then a chance of snow between 7am and 10am, then a chance of snow showers between 10am and 4pm, then rain and snow showers likely. Mostly cloudy, with a high near 45. Northeast wind 0 to 10 mph. Chance of precipitation is 60%.\n",
            "- Wednesday Night: Rain and snow showers likely before 10pm, then a chance of rain and snow. Mostly cloudy, with a low around 32. North wind 5 to 10 mph. Chance of precipitation is 60%.\n",
            "- Thursday: A chance of snow before 1pm, then scattered rain and snow showers. Mostly cloudy, with a high near 44. Northwest wind 5 to 10 mph. Chance of precipitation is 50%.\n",
            "- Thursday Night: Scattered rain and snow showers before 10pm, then snow likely. Mostly cloudy, with a low around 33. Northwest wind 10 to 15 mph. Chance of precipitation is 60%. New snow accumulation of less than half an inch possible.\n",
            "- Friday: Snow likely before 10am, then rain likely. Mostly cloudy, with a high near 44. Chance of precipitation is 70%. New snow accumulation of less than half an inch possible.\n",
            "- Friday Night: A chance of rain before 10pm, then a chance of rain and snow. Mostly cloudy, with a low around 30.\n",
            "- Saturday: A chance of rain and snow. Mostly cloudy, with a high near 46.\n",
            "- Saturday Night: A chance of rain. Cloudy, with a low around 32.\n",
            "- Sunday: Rain likely. Cloudy, with a high near 44.\n",
            "- Sunday Night: Rain likely. Cloudy, with a low around 34.\n",
            "- Monday: Rain likely. Mostly cloudy, with a high near 46.\n",
            "- Monday Night: A chance of rain. Mostly cloudy, with a low around 34.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agents\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import base64\n",
        "import google.generativeai as genai2\n",
        "import google.ai.generativelanguage as glm # For Schema/Type\n",
        "import requests\n",
        "import datetime\n",
        "import json # Good practice\n",
        "\n",
        "def validation_model(agent_prompt, evaluation_text):\n",
        "  client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=\"qwiklabs-gcp-01-3005c83a3aae\",\n",
        "      location=\"us-central1\",\n",
        "  )\n",
        "\n",
        "  model = \"gemini-2.0-flash-lite-001\"\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        types.Part.from_text(text=evaluation_text)\n",
        "      ]\n",
        "    ),\n",
        "  ]\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    max_output_tokens = 1346,\n",
        "    response_modalities = [\"TEXT\"],\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"OFF\"\n",
        "    )],\n",
        "    system_instruction=[types.Part.from_text(text=agent_prompt)],\n",
        "  )\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "          model=model,\n",
        "          contents=contents,\n",
        "          config = generate_content_config,\n",
        "        )\n",
        "  # print(\"validation:\",response.text)\n",
        "  string_res = response.text.lower().strip()\n",
        "  if string_res == \"true\":\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def input_validation_agent(user_input):\n",
        "  input_agent = \"\"\"\n",
        "  You are a prompt safety validation agent that evaluates at incoming queries and returns \\\"true\\\" if safe and \\\"false\\\" if not safe.\n",
        "  Things like threats or violence are not safe.\n",
        "  'I want to make a threat' = 'false'\n",
        "  \"\"\"\n",
        "  return validation_model(input_agent, user_input)\n",
        "\n",
        "def output_validation_agent(model_output):\n",
        "  output_agent = \"\"\"\n",
        "  You are a model output safety validation agent that evaluates at outgoing reponses and returns \\\"true\\\" if safe and \\\"false\\\" if not safe.\n",
        "  Bad outgoing response may include things that may affect the user in a negative way would be deemed not safe.\n",
        "  'I hate you' == 'false'\n",
        "  \"\"\"\n",
        "  return validation_model(output_agent, model_output)\n",
        "\n",
        "# with function calling to weather agency\n",
        "def response_model(user_input):\n",
        "  client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=\"qwiklabs-gcp-01-3005c83a3aae\",\n",
        "      location=\"us-central1\",\n",
        "  )\n",
        "\n",
        "  si_text1 = \"\"\"\n",
        "  You a helpful chatbot for people asking common questions about Alaska Department of Snow (ADS).\n",
        "  Only respond to questions about Alaska according to the relevant information provided.\n",
        "  If asked about the weather use your tool to get the forecast information for Alaska.\n",
        "  \"\"\"\n",
        "\n",
        "  # print(user_input)\n",
        "\n",
        "  model_name = \"gemini-2.0-flash-lite-001\"\n",
        "  # model_name = \"gemini-2.5-pro-preview-03-25\"\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        types.Part.from_text(text=user_input)\n",
        "      ]\n",
        "    ),\n",
        "  ]\n",
        "\n",
        "  generate_content_config_with_tools = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    seed = 0,\n",
        "    max_output_tokens = 8192,\n",
        "    response_modalities = [\"TEXT\"],\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    )],\n",
        "    system_instruction=[types.Part.from_text(text=si_text1)],\n",
        "    tools = [weather_tool],\n",
        "  )\n",
        "\n",
        "  generate_content_config_without_tools = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    seed = 0,\n",
        "    max_output_tokens = 1346,\n",
        "    response_modalities = [\"TEXT\"],\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    )],\n",
        "    system_instruction=[types.Part.from_text(text=si_text1)],\n",
        "  )\n",
        "\n",
        "  # response = client.models.generate_content(\n",
        "  #         model=model,\n",
        "  #         contents=contents,\n",
        "  #         config = generate_content_config,\n",
        "  #       )\n",
        "  # print(\"response:\",response.text)\n",
        "  # response_function_call = response.candidates[0].content.parts[0].function_call\n",
        "  # print(f\"Model response includes function call: {response_function_call}\")\n",
        "  # return response.text\n",
        "  available_functions = {\n",
        "    \"get_weather\": get_weather,\n",
        "  }\n",
        "\n",
        "  # model = client.get_generative_model(model_id=model_name)\n",
        "\n",
        "  try:\n",
        "    # Send the initial prompt and available tools to the model\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "          model=model_name,\n",
        "          contents=contents,\n",
        "          config = generate_content_config_with_tools,\n",
        "        )\n",
        "    # print(\"response\",response.text)\n",
        "    # print(\"response_part\",response.candidates[0].content.parts[0])\n",
        "\n",
        "    # return response.text if response.text\n",
        "    # Check if the model's response includes a function call request\n",
        "    response_part = response.candidates[0].content.parts[0]\n",
        "\n",
        "    # === Loop for potential multi-turn function calls (optional but good practice) ===\n",
        "    # While the model requests a function call...\n",
        "    if response_part.function_call:\n",
        "        function_call = response_part.function_call\n",
        "        function_name = function_call.name\n",
        "        function_args = function_call.args # This is already a dict\n",
        "\n",
        "        print(f\"Gemini requested Function Call: {function_name}({function_args})\")\n",
        "\n",
        "        # --- Execute the *actual* function ---\n",
        "        if function_name in available_functions:\n",
        "            # Get the appropriate function from our map\n",
        "            function_to_call = available_functions[function_name]\n",
        "\n",
        "            # Call the function with the arguments provided by the model\n",
        "            # Using ** automatically unpacks the dict keys/values as arguments\n",
        "            try:\n",
        "                function_response_data = function_to_call()\n",
        "                print(f\"--> Function Execution Result: {function_response_data}\")\n",
        "\n",
        "                # --- Send the function's *result* back to the model ---\n",
        "                # We need to format the result in a way Gemini understands\n",
        "                # The SDK provides Part.from_function_response for this\n",
        "                function_response_part = types.Part.from_function_response(\n",
        "                    name=function_name,\n",
        "                    response={ # The 'response' field expects a dict\n",
        "                        \"content\": function_response_data,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                # Send the function response back, including the previous context\n",
        "                # The history includes the user prompt and the model's function call request\n",
        "                print(\"--- Sending function result back to Gemini ---\")\n",
        "                new_contents = f\"{user_input}\\n\\n {function_response_data}\"\n",
        "                response = client.models.generate_content(\n",
        "                    contents = new_contents,\n",
        "                    model=model_name,\n",
        "                    config = generate_content_config_without_tools,\n",
        "                )\n",
        "\n",
        "                return response.text\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error executing function {function_name}: {e}\")\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(f\"Error: Gemini requested unknown function '{function_name}'\")\n",
        "            # Handle case where model hallucinates a function name\n",
        "            # You might send a response indicating the function isn't available.\n",
        "            return response_part.text\n",
        "    else:\n",
        "      return response.text\n",
        "\n",
        "\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during Gemini interaction: {e}\")\n",
        "    print(\"Full Response (if available):\", response if 'response' in locals() else 'N/A')\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "print(response_model(\"Help with weather\"))\n",
        "# print(output_validation_agent(\"hello\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWRqaZFOYdFu",
        "outputId": "494751de-d09c-4124-fa7a-245a2a29873b"
      },
      "id": "OWRqaZFOYdFu",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini requested Function Call: get_weather({})\n",
            "--> Function Execution Result: Weather Report for Kodiak, AK at 2025-04-29 22:54:03:\n",
            "\n",
            "- This Afternoon: Snow showers likely. Mostly cloudy, with a high near 42. South wind around 10 mph, with gusts as high as 25 mph. Chance of precipitation is 70%.\n",
            "- Tonight: Snow showers likely before 7pm, then rain and snow showers likely. Mostly cloudy, with a low around 33. Southeast wind 5 to 10 mph, with gusts as high as 25 mph. Chance of precipitation is 70%.\n",
            "- Wednesday: A chance of snow showers before 7am, then a chance of snow between 7am and 10am, then a chance of snow showers between 10am and 4pm, then rain and snow showers likely. Mostly cloudy, with a high near 45. Northeast wind 0 to 10 mph. Chance of precipitation is 60%.\n",
            "- Wednesday Night: Rain and snow showers likely before 10pm, then a chance of rain and snow. Mostly cloudy, with a low around 32. North wind 5 to 10 mph. Chance of precipitation is 60%.\n",
            "- Thursday: A chance of snow before 1pm, then scattered rain and snow showers. Mostly cloudy, with a high near 44. Northwest wind 5 to 10 mph. Chance of precipitation is 50%.\n",
            "- Thursday Night: Scattered rain and snow showers before 10pm, then snow likely. Mostly cloudy, with a low around 33. Northwest wind 10 to 15 mph. Chance of precipitation is 60%. New snow accumulation of less than half an inch possible.\n",
            "- Friday: Snow likely before 10am, then rain likely. Mostly cloudy, with a high near 44. Chance of precipitation is 70%. New snow accumulation of less than half an inch possible.\n",
            "- Friday Night: A chance of rain before 10pm, then a chance of rain and snow. Mostly cloudy, with a low around 30.\n",
            "- Saturday: A chance of rain and snow. Mostly cloudy, with a high near 46.\n",
            "- Saturday Night: A chance of rain. Cloudy, with a low around 32.\n",
            "- Sunday: Rain likely. Cloudy, with a high near 44.\n",
            "- Sunday Night: Rain likely. Cloudy, with a low around 34.\n",
            "- Monday: Rain likely. Mostly cloudy, with a high near 46.\n",
            "- Monday Night: A chance of rain. Mostly cloudy, with a low around 34.\n",
            "\n",
            "--- Sending function result back to Gemini ---\n",
            "Okay, here's the weather forecast for Kodiak, AK:\n",
            "\n",
            "*   **Today:** Snow showers likely with a high near 42°F and a south wind.\n",
            "*   **Tonight:** Snow showers likely before 7 pm, then rain and snow showers likely, with a low around 33°F.\n",
            "*   **Wednesday:** A chance of snow showers, then rain and snow showers likely, with a high near 45°F.\n",
            "*   **Wednesday Night:** Rain and snow showers likely, with a low around 32°F.\n",
            "*   **Thursday:** A chance of snow, then scattered rain and snow showers, with a high near 44°F.\n",
            "*   **Thursday Night:** Scattered rain and snow showers, then snow likely, with a low around 33°F. Possible snow accumulation of less than half an inch.\n",
            "*   **Friday:** Snow likely before 10 am, then rain likely, with a high near 44°F. Possible snow accumulation of less than half an inch.\n",
            "*   **Friday Night:** A chance of rain, with a low around 30°F.\n",
            "*   **Saturday:** A chance of rain and snow, with a high near 46°F.\n",
            "*   **Saturday Night:** A chance of rain, with a low around 32°F.\n",
            "*   **Sunday:** Rain likely, with a high near 44°F and a low around 34°F.\n",
            "*   **Monday:** Rain likely, with a high near 46°F and a chance of rain at night.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# main\n",
        "def main(user_input):\n",
        "  input_validation_model_response = input_validation_agent(user_input)\n",
        "  # print(\"input validation\",input_validation_model_response)\n",
        "  if input_validation_model_response == False:\n",
        "    return \"Error, please ask a question about taxes\"\n",
        "\n",
        "  # runs vector search for closes 5 embeddings\n",
        "  search_results = vector_search(user_input)\n",
        "\n",
        "  # formats the prompt with user question and 5 FAQs\n",
        "  formatted_prompt = format_prompt(user_input, search_results)\n",
        "  # print(formatted_prompt)\n",
        "\n",
        "  # sends formated prompt to gemini to construct a response to the answer\n",
        "\n",
        "  run_response = response_model(formatted_prompt)\n",
        "  # print(run_response)\n",
        "  if run_response:\n",
        "    output_validation_model_response = output_validation_agent(run_response)\n",
        "    # print(\"output validation\", output_validation_model_response)\n",
        "  else:\n",
        "    return \"ERROR\"\n",
        "\n",
        "  if output_validation_model_response == True:\n",
        "    return run_response\n",
        "  else:\n",
        "    return \"Error, please try again for a better response\"\n",
        "\n",
        "\n",
        "#user question\n",
        "user_input = \"What is the best way to contact ADS?\"\n",
        "\n",
        "\n",
        "print(f\"Question: {user_input}\\n--------------------------------\\n\\n\")\n",
        "print(main(user_input))\n",
        "# print(output_validation_agent(\"no I hate you.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okmk2ZE3dZP4",
        "outputId": "731d5f4b-519b-4bf1-a515-03b6da1f927a"
      },
      "id": "okmk2ZE3dZP4",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the best way to contact ADS?\n",
            "--------------------------------\n",
            "\n",
            "\n",
            "You can contact ADS by calling their toll-free number 1-800-SNOW-ADS (1-800-766-9237) for general information and to be redirected to your local office.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear cache artifacts\n",
        "print(\"Clearing pytest cache...\")\n",
        "!pytest --cache-clear\n",
        "print(\"Cache cleared.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9enTdzYqhy7",
        "outputId": "002aa73d-a6c8-4e10-924d-03b0c65d3a29"
      },
      "id": "u9enTdzYqhy7",
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing pytest cache...\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.4, pluggy-1.5.0\n",
            "rootdir: /content\n",
            "plugins: anyio-4.9.0, typeguard-4.4.1\n",
            "collected 0 items                                                                                  \u001b[0m\n",
            "\n",
            "\u001b[33m====================================== \u001b[33mno tests ran\u001b[0m\u001b[33m in 0.00s\u001b[0m\u001b[33m =======================================\u001b[0m\n",
            "Cache cleared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unit tests\n",
        "import pytest\n",
        "import ipytest\n",
        "ipytest.autoconfig()\n",
        "\n",
        "def test_employment_classification():\n",
        "  assert True == True\n",
        "\n",
        "# test overall functionality of workflow\n",
        "def test_functionality():\n",
        "  response = main(\"weather\")\n",
        "  assert response != \"\"\n",
        "  assert \"Error\" not in response\n",
        "\n",
        "# test individual agents\n",
        "test_data = [\n",
        "    # (input_value, expected_output)\n",
        "    # input_validation_agent\n",
        "    (input_validation_agent, \"Who leads the ADS\", True),\n",
        "    (input_validation_agent, \"Can I make a threat to an employee\", False),\n",
        "\n",
        "    # output_validation_agent\n",
        "    (output_validation_agent, \"Yes, I can help you answer that question\", True),\n",
        "    (output_validation_agent, \"no I hate you.\", False),\n",
        "]\n",
        "\n",
        "@pytest.mark.parametrize(\"agent_func, input_val, expected\", test_data)\n",
        "def test_agent_processing_generic(agent_func, input_val, expected):\n",
        "  \"\"\"Tests multiple agents using a generic structure.\"\"\"\n",
        "  agent_name = agent_func.__name__ # Get the function name for clarity\n",
        "  print(f\"Testing {agent_name} with input: {repr(input_val)}\")\n",
        "  assert agent_func(input_val) == expected\n",
        "\n",
        "\n",
        "# test vector search\n",
        "def test_vector_search():\n",
        "  search_results = vector_search(\"who leads the ADS\")\n",
        "  print(search_results)\n",
        "  assert len(search_results) > 0\n",
        "\n",
        "# test prompt formatting\n",
        "def test_prompt_formatting():\n",
        "  vector_data = [{'query': 'weather', 'question': 'Where does ADS get its weather forecasts?', 'answer': 'ADS partners with the National Weather Service and maintains localized weather monitoring stations for more precise data across diverse regions.'}, {'query': 'weather', 'question': 'How do schools typically learn about impending storms?', 'answer': 'ADS shares forecast data with school districts, which helps superintendents decide on closures or delays based on road safety and storm severity.'}, {'query': 'weather', 'question': 'How can I check current road conditions statewide?', 'answer': 'Use the ADS “SnowLine” app or visit the official ADS website’s road conditions dashboard, which is updated hourly with closures and warnings.'}, {'query': 'weather', 'question': 'Does ADS oversee school closure decisions?', 'answer': 'While ADS provides data on snow conditions, final school closure decisions are made by local school districts. ADS coordinates closely to keep them informed.'}, {'query': 'weather', 'question': 'Can I request data on ADS’s annual snowfall measurements?', 'answer': 'Yes. ADS publishes annual snowfall reports and statistics on its website. You can also file a public records request for more detailed data.'}]\n",
        "  question = \"what is the weather forcast\"\n",
        "  formatted_prompt = format_prompt(question, vector_data)\n",
        "  print(formatted_prompt)\n",
        "  expected_header = f\"User Query: {question} \\n\\nUse the relevant information below to help the user:\"\n",
        "\n",
        "  assert expected_header in formatted_prompt\n",
        "  assert \"Question:\" in formatted_prompt\n",
        "  assert \"Answer:\" in formatted_prompt\n",
        "\n",
        "# test llm function\n",
        "def test_get_weather():\n",
        "  assert get_weather() != \"\"\n",
        "\n",
        "ipytest.run(\"-vv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze89mdCfnks7",
        "outputId": "bc4cbe87-02a2-4b9a-a7ef-8c23c2cfc608"
      },
      "id": "ze89mdCfnks7",
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.4, pluggy-1.5.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: anyio-4.9.0, typeguard-4.4.1\n",
            "\u001b[1mcollecting ... \u001b[0mcollected 9 items\n",
            "\n",
            "t_95fe86b18c5543dea730302f5095294d.py::test_employment_classification \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 11%]\u001b[0m\n",
            "t_95fe86b18c5543dea730302f5095294d.py::test_functionality \u001b[32mPASSED\u001b[0m\u001b[32m                             [ 22%]\u001b[0m\n",
            "t_95fe86b18c5543dea730302f5095294d.py::test_agent_processing_generic[input_validation_agent-Who leads the ADS-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
            "t_95fe86b18c5543dea730302f5095294d.py::test_agent_processing_generic[input_validation_agent-Can I make a threat to an employee-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
            "t_95fe86b18c5543dea730302f5095294d.py::test_agent_processing_generic[output_validation_agent-Yes, I can help you answer that question-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
            "t_95fe86b18c5543dea730302f5095294d.py::test_agent_processing_generic[output_validation_agent-no I hate you.-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
            "t_95fe86b18c5543dea730302f5095294d.py::test_vector_search \u001b[32mPASSED\u001b[0m\u001b[32m                             [ 77%]\u001b[0m\n",
            "t_95fe86b18c5543dea730302f5095294d.py::test_prompt_formatting \u001b[32mPASSED\u001b[0m\u001b[32m                         [ 88%]\u001b[0m\n",
            "t_95fe86b18c5543dea730302f5095294d.py::test_get_weather \u001b[32mPASSED\u001b[0m\u001b[32m                               [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 8.22s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ExitCode.OK: 0>"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# google evaluation api evaluation\n",
        "from vertexai.evaluation import (\n",
        "    MetricPromptTemplateExamples,\n",
        "    EvalTask,\n",
        "    PairwiseMetric,\n",
        "    PairwiseMetricPromptTemplate,\n",
        "    PointwiseMetric,\n",
        "    PointwiseMetricPromptTemplate,\n",
        ")\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "def model_evaluation():\n",
        "\n",
        "  topics = [\n",
        "      \"Tell me about the mayor\",\n",
        "      \"Are the roads closed due to snow?\",\n",
        "      \"Is Doug in office?\"\n",
        "  ]\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for topic in topics:\n",
        "    result = main(topic)\n",
        "    results.append(result)\n",
        "\n",
        "  eval_dataset = pd.DataFrame({\n",
        "    \"prompt\": topics,\n",
        "  })\n",
        "\n",
        "  eval_task = EvalTask(\n",
        "    dataset=eval_dataset,\n",
        "    metrics=[MetricPromptTemplateExamples.Pointwise.GROUNDEDNESS,\n",
        "             MetricPromptTemplateExamples.Pointwise.COHERENCE\n",
        "             ],\n",
        "    experiment=\"apartment-listing-generation\",\n",
        "  )\n",
        "\n",
        "  model = GenerativeModel(\n",
        "    \"gemini-2.0-flash-001\",\n",
        "    generation_config={\n",
        "        \"temperature\": 0,\n",
        "        \"top_p\": 0.4,\n",
        "    },\n",
        "  )\n",
        "\n",
        "  run_ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  eval_result = eval_task.evaluate(\n",
        "    model=model,\n",
        "    experiment_run_name=f\"apt-gen-{run_ts}\"\n",
        "    )\n",
        "  eval_result.metrics_table\n",
        "  # print(eval_result.metrics_table)\n",
        "  print(\"eval obj\",eval_result)\n",
        "\n",
        "model_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "buWBtbGmsWlm",
        "outputId": "36ab54f1-b7d9-40eb-be82-294e96763071"
      },
      "id": "buWBtbGmsWlm",
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-97895dba-5edb-4496-b7c4-f6651eac5710\" href=\"#view-view-vertex-resource-97895dba-5edb-4496-b7c4-f6651eac5710\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-97895dba-5edb-4496-b7c4-f6651eac5710');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/apartment-listing-generation/runs?project=qwiklabs-gcp-01-3005c83a3aae');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/apartment-listing-generation/runs?project=qwiklabs-gcp-01-3005c83a3aae', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/953893243677/locations/us-central1/metadataStores/default/contexts/apartment-listing-generation-apt-gen-20250429-220635 to Experiment: apartment-listing-generation\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-81d2d1c9-c704-4d58-9480-cb7464e68c3c\" href=\"#view-view-vertex-resource-81d2d1c9-c704-4d58-9480-cb7464e68c3c\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment Run</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-81d2d1c9-c704-4d58-9480-cb7464e68c3c');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/apartment-listing-generation/runs/apartment-listing-generation-apt-gen-20250429-220635?project=qwiklabs-gcp-01-3005c83a3aae');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/apartment-listing-generation/runs/apartment-listing-generation-apt-gen-20250429-220635?project=qwiklabs-gcp-01-3005c83a3aae', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.evaluation.eval_task:Logging Eval Experiment metadata: {'model_name': 'publishers/google/models/gemini-2.0-flash-001', 'temperature': 0, 'top_p': 0.4}\n",
            "INFO:vertexai.evaluation._evaluation:Generating a total of 3 responses from Gemini model gemini-2.0-flash-001.\n",
            "100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n",
            "INFO:vertexai.evaluation._evaluation:All 3 responses are successfully generated from Gemini model gemini-2.0-flash-001.\n",
            "INFO:vertexai.evaluation._evaluation:Multithreaded Batch Inference took: 1.7158870269995532 seconds.\n",
            "INFO:vertexai.evaluation._evaluation:Computing metrics with a total of 6 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n",
            "INFO:vertexai.evaluation._evaluation:All 6 metric requests are successfully computed.\n",
            "INFO:vertexai.evaluation._evaluation:Evaluation Took:6.639314342999569 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval obj EvalResult(summary_metrics={'row_count': 3, 'groundedness/mean': 0.6666666666666666, 'groundedness/std': 0.5773502691896258, 'coherence/mean': 5.0, 'coherence/std': 0.0}, metrics_table=                              prompt  \\\n",
            "0            Tell me about the mayor   \n",
            "1  Are the roads closed due to snow?   \n",
            "2                 Is Doug in office?   \n",
            "\n",
            "                                            response  \\\n",
            "0  To give you the best information about the may...   \n",
            "1  I do not have access to real-time information,...   \n",
            "2  To give you the most accurate answer, I need t...   \n",
            "\n",
            "                            groundedness/explanation  groundedness/score  \\\n",
            "0  The response does not contain any information ...                 1.0   \n",
            "1  The response does not contain any information ...                 1.0   \n",
            "2  The response provides information (Doug Ford, ...                 0.0   \n",
            "\n",
            "                               coherence/explanation  coherence/score  \n",
            "0  The response is completely coherent because it...              5.0  \n",
            "1  The response directly addresses the user's que...              5.0  \n",
            "2  The response is completely coherent because it...              5.0  , metadata={'experiment': 'apartment-listing-generation', 'experiment_run': 'apt-gen-20250429-220635'})\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-02-509de7e9a426 (Apr 28, 2025, 10:10:27 AM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}