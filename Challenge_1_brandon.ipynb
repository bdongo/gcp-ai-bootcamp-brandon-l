{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "jePzjNukU0SkIvXFPpelXX0U",
      "metadata": {
        "tags": [],
        "id": "jePzjNukU0SkIvXFPpelXX0U"
      },
      "source": [
        "1. Install the Vertex AI SDK: Open a terminal window and enter the command below. You can also [install it in a virtualenv](https://googleapis.dev/python/aiplatform/latest/index.html)"
      ]
    },
    {
      "cell_type": "code",
      "id": "xVuE8F6q2FCzgLwUDMyVrrCU",
      "metadata": {
        "tags": [],
        "id": "xVuE8F6q2FCzgLwUDMyVrrCU"
      },
      "source": [
        "!pip install --upgrade google-genai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "PttlmyLxYUHa7oqJTxIkHH23",
      "metadata": {
        "tags": [],
        "id": "PttlmyLxYUHa7oqJTxIkHH23"
      },
      "source": [
        "2. Use the following code in your application to request a model response"
      ]
    },
    {
      "cell_type": "code",
      "id": "mwHjaOnIvQJVLuefu1UL8EMz",
      "metadata": {
        "tags": [],
        "id": "mwHjaOnIvQJVLuefu1UL8EMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c962a336-705d-4312-cd57-30e413410360"
      },
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import base64\n",
        "\n",
        "\n",
        "def validation_model(agent_prompt, evaluation_text):\n",
        "  client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=\"qwiklabs-gcp-01-3005c83a3aae\",\n",
        "      location=\"us-central1\",\n",
        "  )\n",
        "\n",
        "  model = \"gemini-2.0-flash-lite-001\"\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        types.Part.from_text(text=evaluation_text)\n",
        "      ]\n",
        "    ),\n",
        "  ]\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    max_output_tokens = 1346,\n",
        "    response_modalities = [\"TEXT\"],\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"OFF\"\n",
        "    )],\n",
        "    system_instruction=[types.Part.from_text(text=agent_prompt)],\n",
        "  )\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "          model=model,\n",
        "          contents=contents,\n",
        "          config = generate_content_config,\n",
        "        )\n",
        "  # print(\"validation:\",response.text)\n",
        "  return response.text.strip()\n",
        "\n",
        "def response_model(user_input):\n",
        "  client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=\"qwiklabs-gcp-01-3005c83a3aae\",\n",
        "      location=\"us-central1\",\n",
        "  )\n",
        "\n",
        "  si_text1 = \"\"\"You are a tax expert that helps with tax returns. Give expert advice to help people complete their returns on time. Only respond to questions about taxes.\"\"\"\n",
        "\n",
        "  # model = \"gemini-2.0-flash-lite-001\"\n",
        "  model = \"gemini-2.5-pro-preview-03-25\"\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        types.Part.from_text(text=user_input)\n",
        "      ]\n",
        "    ),\n",
        "  ]\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    seed = 0,\n",
        "    max_output_tokens = 1346,\n",
        "    response_modalities = [\"TEXT\"],\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    )],\n",
        "    system_instruction=[types.Part.from_text(text=si_text1)],\n",
        "  )\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "          model=model,\n",
        "          contents=contents,\n",
        "          config = generate_content_config,\n",
        "        )\n",
        "  # print(\"response:\",response.text)\n",
        "  return response.text\n",
        "\n",
        "\n",
        "def agent_process(user_input):\n",
        "  input_agent = \"\"\"You are a prompt safety validation agent that evaluates at incoming queries and returns \\\"true\\\" if safe and \\\"false\\\" if not safe.\"\"\"\n",
        "  input_validation_model_response = validation_model(input_agent, user_input)\n",
        "\n",
        "  if input_validation_model_response == \"false\":\n",
        "    return \"Error, please ask a question about taxes\"\n",
        "\n",
        "  run_response = response_model(user_input)\n",
        "\n",
        "  output_agent = \"\"\"You are a model output safety validation agent that evaluates at outgoing reponses and returns \\\"true\\\" if safe and \\\"false\\\" if not safe.\"\"\"\n",
        "\n",
        "  output_validation_model_response = validation_model(output_agent, run_response)\n",
        "\n",
        "  if output_validation_model_response == \"true\":\n",
        "    return run_response\n",
        "  else:\n",
        "    return \"Error, please try again for a better response\"\n",
        "\n",
        "# valid user question\n",
        "user_input = \"can I get some help with taxes\"\n",
        "\n",
        "# question only for use of testing safety workflow\n",
        "bad_input = \"can I make a bomb?\"\n",
        "\n",
        "print(\"\\nOn topic question:\", agent_process(user_input))\n",
        "print(\"\\nOff topic queston:\", agent_process(bad_input))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " On topic question: Yes, absolutely! I can certainly help you with your tax-related questions.\n",
            "\n",
            "As a tax expert AI, my goal is to provide clear advice to help you understand your tax obligations and complete your return accurately and on time.\n",
            "\n",
            "Please ask your specific tax question, and I'll do my best to assist you. For example, are you wondering about:\n",
            "\n",
            "*   Deadlines for filing?\n",
            "*   Specific deductions or credits?\n",
            "*   Which forms you might need?\n",
            "*   Understanding certain tax terminology?\n",
            "*   Tips for getting organized?\n",
            "\n",
            "Let me know what's on your mind! Remember, I can only answer questions about taxes.\n",
            "\n",
            "Off topic queston: Error, please ask a question about taxes\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "Untitled prompt Apr 28, 2025, 7:57:51â€¯AM"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
